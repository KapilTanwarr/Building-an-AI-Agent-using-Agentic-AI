# 📈 Agentic AI for Stock Trading with Deep Q-Learning

This project shows how to build a goal-driven AI trading agent that can learn, reason, and act — using Agentic AI principles and Deep Reinforcement Learning.

We’re not just predicting prices. We're training an agent to make decisions, learn from experience, and maximize profit — in a simulated stock market environment.

## 🧠 What This Project Does

✅ Builds a goal-oriented trading agent using Python and PyTorch
✅ Uses Deep Q-Learning to learn trading strategies
✅ Simulates a realistic trading environment using historical stock data
✅ Uses states (technical indicators), actions (Buy/Sell/Hold), and rewards (profit/loss)
✅ Demonstrates how Agentic AI applies to financial decision-making

## 🚀 Key Features

🧠 Autonomous agent with its own goal: maximize trading profit
🧮 Learns from environment feedback using Q-Learning
📊 Uses real AAPL stock data and technical indicators
🔁 Multi-step decision-making with memory and exploration
📜 Logs profit/loss over episodes to track learning progress

## 🛠️ Tech Stack

Python 3.x
PyTorch
Pandas, NumPy
yfinance (for stock data)
No frameworks like LangChain — this is raw RL logic

## 🧩 Core Concepts

Concept	Description
🎯 Goal	Maximize profit over a trading episode
🧠 Agent	Deep Q-Network (DQN) making decisions
🌍 Environment	Stock market simulator with prices, SMAs, returns
🔁 Loop	State → Action → Reward → New State → Learn
💰 Reward	Final portfolio value minus starting capital


## ✨ Use Cases

Financial trading simulations
RL-based strategy evaluation
Teaching tool for DQN and Agentic AI
Base for building more advanced trading agents
Experiments with reward shaping, feature engineering, etc.

## 🧠 What You’ll Learn

How to build an AI trading agent using reinforcement learning
How to simulate an environment with real data
How Agentic AI applies to decision-making systems
How rewards, states, and actions interact in Q-learning
How to build, train, and debug a DQN from scratch

## 🏗️ Next Steps / Extensions

Add more technical indicators (MACD, RSI, etc.)
Use a sliding window of past prices as state
Train on multiple stocks
Add transaction costs and slippage
Replace DQN with PPO or Transformer-based agents


## Kapil Tanwar
### Data Scientist | AI/ML Engineer | RL + LLMs Explorer

### "Don’t predict the market. Train an agent to play it."
